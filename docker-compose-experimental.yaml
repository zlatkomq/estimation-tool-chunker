services:
  docling-inference:
    build: .
    image: docling-inference:latest
    ports:
      - 8878:8080
    environment:
      - DEV_MODE=0
      - AUTH_TOKEN=dev-key
      - NUM_WORKERS=4  # Optimal for RTX 4090
      - DOCLING_OCR_ENGINE=tesseract
      - DOCLING_DISABLE_EASYOCR=1
      - TESSERACT_DEVICE=cuda
      - DOCLING_TABLE_EXTRACTION_MODE=tableformer
      - DOCLING_USE_FP16=true
      - BATCH_SIZE=32
      - TORCH_CUDA_ARCH_LIST=8.9
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG  # Set to maximum verbosity
      - DOCLING_LOG_LEVEL=DEBUG  # Set docling package to debug level
    init: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
      restart_policy:
        condition: on-failure
        max_attempts: 5
        delay: 5s
    volumes:
      - ./logs:/app/logs
      - hf_cache:/root/.cache/huggingface
      - ocr_cache:/root/.EasyOCR
    healthcheck:
      test: ["CMD-SHELL", "nvidia-smi && python /app/check_gpu.py"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: >
      bash -c "mkdir -p /root/.EasyOCR/model &&
              chmod -R 777 /root/.EasyOCR &&
              /app/.venv/bin/python -m src.main"
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        mode: "non-blocking"
        tag: "{{.Name}}"

volumes:
  hf_cache:
  ocr_cache:
