services:
  docling-inference:
    build: .
    image: docling-inference:latest
    ports:
      - 8878:8080
    environment:
      - DEV_MODE=0
      - AUTH_TOKEN=dev-key
      - NUM_WORKERS=4  # Optimal for RTX 4090
      - DOCLING_OCR_ENGINE=tesseract
      - DOCLING_DISABLE_EASYOCR=1
      - TESSERACT_DEVICE=cuda
      - DOCLING_TABLE_EXTRACTION_MODE=tableformer
      - DOCLING_USE_FP16=true
      - BATCH_SIZE=32
      - TORCH_CUDA_ARCH_LIST=8.9
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG  # Set to maximum verbosity
      - DOCLING_LOG_LEVEL=DEBUG  # Set docling package to debug level
      - DOCLING_PRELOAD_MODELS=true

    init: true
    restart: on-failure:5
    # Standard Docker Compose GPU access
    runtime: nvidia
    # Alternative GPU access configuration
    # device_requests:
    #   - count: 1
    #     capabilities: [gpu]
    volumes:
      - ./logs:/app/logs
      - hf_cache:/root/.cache/huggingface
      - ocr_cache:/root/.EasyOCR
    command: >
      bash -c "mkdir -p /root/.EasyOCR/model &&
              chmod -R 777 /root/.EasyOCR &&
              /app/.venv/bin/python -m src.main"
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        mode: "non-blocking"
        tag: "{{.Name}}"

volumes:
  hf_cache:
  ocr_cache: 